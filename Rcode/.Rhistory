source("00Require.R")
url <- "https://www.buzzfeed.com/?country=us"
browseURL(url)
url_parsed <- read_html(url)
class(url_parsed)
html_structure(url_parsed)
as_list(url_parsed)
# 3. extract specific nodes with CSS (or XPath)
headings_nodes <- html_nodes(url_parsed, css = ".lede__link")
# 4. extract content from nodes
headings <- html_text(headings_nodes)
url_parsed <- read_html(url)
url_parsed <- read_html("BuzzFeed.html")
authors <- html_nodes(url_parsed, css = ".small-meta__item:nth-child(1) a") %>% html_text()
table(authors) %>% sort(decreasing = T) %>% data.frame()%>% datatable()
trump_views <- article_pageviews(project = "en.wikipedia", article = "Donald Trump", user_type = "user", start = "20150101", end = "20160803")
trump_views <- article_pageviews(project = "en.wikipedia", article = "Donald Trump",
user_type = "user", start = "20150101", end = "20161214")
trump<-trump_views%>%select(timestamp,views)
